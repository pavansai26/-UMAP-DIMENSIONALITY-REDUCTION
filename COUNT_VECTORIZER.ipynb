{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNJGgyHbKWBsidXiY7t84Mn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavansai26/-UMAP-DIMENSIONALITY-REDUCTION/blob/master/COUNT_VECTORIZER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teXAoLpTjejv"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "url = 'C:\\\\Python Scripts\\\\NLP_projekty\\\\review_clean.csv'\n",
        "dataset = pd.read_csv(url, header=0, index_col=0)\n",
        "\n",
        "# Shape\n",
        "print(dataset.shape)\n",
        "print(dataset.head(5))\n",
        "\n",
        "# Separate into input and output columns\n",
        "X = dataset['Review']\n",
        "y = dataset['Recommended']\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a numerical feature vector for each document:\n",
        "vect = CountVectorizer(min_df=5, ngram_range=(1, 2)).fit(X_train)\n",
        "X_train_vect = vect.transform(X_train)\n",
        "print(len(vect.get_feature_names()))\n",
        "\n",
        "# Create Logistic regression model\n",
        "model = Pipeline([('vect', CountVectorizer(min_df=5, ngram_range=(1, 2))),\n",
        "                   ('tfidf', TfidfTransformer()),\n",
        "                   ('clf', LogisticRegression()), ])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "ytest = np.array(y_test)\n",
        "pred_y = model.predict(X_test)\n",
        "\n",
        "# Evaluate predictions\n",
        "print('accuracy %s' % accuracy_score(pred_y, y_test))\n",
        "print(classification_report(ytest, pred_y))"
      ]
    }
  ]
}