{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UMAP DIMENSIONALITY REDUCTION.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyP2D+cZ/mnRp6gkxzbFgkP+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavansai26/-UMAP-DIMENSIONALITY-REDUCTION/blob/master/UMAP_DIMENSIONALITY_REDUCTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku1_GwcvQRO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris,load_digits\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdXpEMuiQypS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(style='white',context='notebook',rc={'figure.figsize':(14,10)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VSa5B_1STM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkInz5tWToby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('/gdrive/My Drive/Colab Notebooks/Iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5QuKinbU2wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uAW-uHjVS1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=pd.DataFrame(data['Species'])\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj0wkzVGVTKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=pd.DataFrame(data[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']])\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUX6KDyfRc3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import umap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbIkQ667R-Nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reducer=umap.UMAP()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGV_a5k3SHaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding=reducer.fit_transform(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgqcKAB4SOpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKq8kT1OXUgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBMVFZmXiN1",
        "colab_type": "text"
      },
      "source": [
        "the result is an array with 150 samples,but only 2 feature columns(instead of 4 we started with). this is because by default umap reduces down to 2d. each row of the array is 2 dimensional representation of the corresponding flower. thus we can plot the embedding as a standard scatterplot and color bby the target array (since it applies to the transformed data which is in the same order as the original)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_jmCCoIY3eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(embedding[:,0],embedding[:,1])\n",
        "plt.gca().set_aspect('equal','datalim')\n",
        "plt.title('UMAP PROJECTION OF THE IRIS DATA', fontsize=24)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2f2Xy-vZudC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "print(digits.data.shape)\n",
        "plt.gray() \n",
        "plt.matshow(digits.images[0]) \n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCrki97ZbWKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWVkbXASbrHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,ax_array=plt.subplots(20,20)\n",
        "axes=ax_array.flatten()\n",
        "for i, ax in enumerate(axes):\n",
        "  ax.imshow(digits.images[i],cmap='gray_r')\n",
        "plt.setp(axes,xticks=[],yticks=[],frame_on=False)\n",
        "plt.tight_layout(h_pad=0.5,w_pad=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxLxAq3UctVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits_df=pd.DataFrame(digits.data[:,:10])\n",
        "digits_df['digit']=pd.Series(digits.target).map(lambda x: 'Digit {}'.format(x))\n",
        "sns.pairplot(digits_df,hue='digit')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q8YVAZMd4Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reducer1=umap.UMAP(random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPShBTZhe5s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reducer1.fit(digits.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaguxwHEe_mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding1=reducer1.fit_transform(digits.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i8-1qizfGxP",
        "colab_type": "text"
      },
      "source": [
        "now instead of returning an embedding we simply get back the reducer object, now having trained on the data set we passed it. to access the resulting transform we can either look at the embedding_ attribute of the reducer object, or cll transform on the original data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFHc4QNwfrXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#embedding=reducer.transform(digits.data)\n",
        "\n",
        "# verify that the result of calling transform is identical to the accesing the embedding_ attribute\n",
        "\n",
        "assert(np.all(embedding == reducer.embedding_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beQOFXiwgeE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIseLQZohPxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m1RdXwwhab6",
        "colab_type": "text"
      },
      "source": [
        "we now we have a dataset with 1797 rows (one for each hand written digit data sample) but only 2 columns as with the iris example we can now plot the resulting embedding, coloring the data points by the class that they belong to(i.e  the digit they represnt.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEC7okrBiHVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(embedding1[:,0],embedding1[:,1],c=digits.target,cmap='Spectral',s=5)\n",
        "plt.gca().set_aspect('equal','datalim')\n",
        "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
        "plt.title('UMAP PROJECTION OF THE DIGITS DATA SET',fontsize=24)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgByndski_CT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}